# ğŸš¦ RL-Based Smart Traffic Light System for Emergency Response

This document presents a comprehensive project synopsis for developing an intelligent traffic management system that prioritizes emergency vehicles while optimizing civilian traffic flow using reinforcement learning algorithms. The system represents a significant advancement in urban traffic control, combining artificial intelligence with real-time emergency response capabilities to create safer and more efficient city transportation networks.[1]

## ğŸ“‹ Project Information

**ğŸ“ Course:** B.Tech : CSE (AI/ML and IoT) (III YEAR â€“ V SEM) (2025-2026)  
**ğŸ›ï¸ Department:** DEPARTMENT OF COMPUTER ENGINEERING & APPLICATIONS  
**ğŸ« Institution:** GLA University  
**ğŸ“ Address:** 17km Stone, NH-19, Mathura-Delhi Road P.O. Chaumuhan, Mathura â€“ 281406 (Uttar Pradesh) India[1]

### ğŸ‘¥ Team Details

**ğŸ† Team Name:** Suraksha Squad (T40)  
**ğŸ“‹ Project Title:** RL-Based Smart Traffic Light System for Emergency Response

| ğŸ‘¤ Team Member | ğŸ†” University Roll |
|----------------|-------------------|
| Shubhansh Gupta | 2315510204 |
| Rachit Gupta | 2315510159 |
| Manas Kashyap | 2315510114 |

**ğŸ‘¨â€ğŸ« Mentor:** Prof. Yunis Ahmed Lone[1]

### ğŸ“… Version History

| ğŸ”– Version | ğŸ“… Date | âœï¸ Author | ğŸ”„ Change |
|------------|---------|-----------|----------|
| v0.1 | 20 Aug, 2025 | Shubhansh Gupta | Initial Draft |
| v0.5 | 30 Sep, 2025 | Suraksha Squad | Half Project Done |
| v1.0 | 31 Oct, 2025 | Suraksha Squad | Full Project Done |

## ğŸŒŸ Project Overview

### ğŸš¨ Problem Statement

Ambulances, fire trucks and police cars frequently get stuck in heavy traffic. Meanwhile, civilian traffic is mis regulated and results in long waits and traffic jams. This lack of synchronisation leads to longer emergency response times and levels of commuter disgruntlement.[1]

### ğŸ¯ Goal

Develop a traffic light control system using RL that detects and gives priority to emergency vehicles (ambulances, fire trucks, police cars etc.) and also manages the civilian traffic flow to reduce long waits and traffic jams. This also reduces emergency response times.[1]

### âŒ Non-Goals

- Integrate with GPS tracking of vehicles
- Learn optimal signal patterns over time
- Reduce fuel wastage from idling
- Traffic flow prediction
- Integration with city control centers[1]

### ğŸ’ Value Proposition

The proposed system will demonstrate how AI can make city roads both safer and greener. By adaptively clearing intersections for EVs, emergency responders reach destinations faster, while overall traffic delays drop. This means quicker medical assistance and firefighting on one hand, and lower commuter travel times and fuel use on the other. In simulation, we expect to show a marked reduction in EV travel time and improved average throughput, illustrating the benefits of learning-based control over static timing.[1]

## ğŸ¯ Scope and Control

### âœ… In-Scope

- ğŸ§  Development of an RL-based control algorithm (e.g. Deep Q-Network or Policy Gradient) for traffic signals
- ğŸ™ï¸ Simulation of urban traffic (e.g. using SUMO or similar), including vehicle agents and intersections
- ğŸ“ GPS-based emergency vehicle detection logic in the simulation
- âš¡ Dynamic adjustment of signal phases in real time based on RL decisions and EV presence
- ğŸ“Š Backend/data logging to record traffic metrics (waiting times, queue lengths, EV travel times)
- ğŸŒ Connectivity to a "virtual" city traffic center (simulated dashboard/API) for monitoring[1]

### âŒ Out-of-Scope

- ğŸ”§ Physical deployment on real traffic hardware
- ğŸ“± Development of smartphone apps or in-car devices
- ğŸŒ National or multi-city scaling (only a prototype network)
- ğŸš¶ Advanced features like pedestrian scheduling, public transport integration, or payment systems
- ğŸ”¬ Highly detailed vehicle models (we assume ideal sensor data)[1]

### ğŸ”® Assumptions

- ğŸ“¡ Simulated emergency vehicles continuously broadcast location (GPS) and priority status
- ğŸ“ˆ Traffic demand patterns (vehicle arrival rates) can be generated or sourced realistically
- ğŸ¯ The simulation environment reliably reflects key urban traffic dynamics
- ğŸ‘¥ Team members (3Ã—10hr/week) are available as scheduled
- ğŸ› ï¸ External libraries/tools (e.g. TensorFlow/PyTorch, SUMO, Node.js) function as expected[1]

### âš ï¸ Constraints

- â° **Time:** 8-week project duration (âˆ¼2 months)
- ğŸ’» **Resources:** Limited compute for training (no industrial GPU). We may use university servers or cloud credits minimally
- ğŸ¯ **Scope:** Focus on core RL and detection, not full-scale software engineering[1]

### ğŸ”— Dependencies

- ğŸ’» **Software:** Traffic simulation framework (e.g. SUMO), RL libraries (TensorFlow/PyTorch), mapping/GPS APIs if needed
- ğŸ“Š **Data:** Road network map data or synthetic scenario generation
- ğŸ–¥ï¸ **Hardware:** Compute resources for RL training; lab computers for integration
- ğŸ‘¨â€ğŸ« **Stakeholder input:** Guidance from faculty mentor[1]

### âœ… Acceptance Criteria (Signoff Scenarios)

- ğŸš‘ **EMERGENCY PATH CLEARING:** GIVEN a simulated ambulance approaching an intersection, WHEN it enters the detection zone, THEN the light on its approach turns green within seconds of detection, and EV passes without halting
- ğŸ“Š **TRAFFIC OPTIMIZATION:** GIVEN a heavy-flow scenario (no EVs), WHEN the RL controller runs for some episodes, THEN the average queue length per intersection is overall decreased
- âš–ï¸ **BALANCED DELAY:** GIVEN simultaneous civilian and emergency vehicles, WHEN EV has right-of-way, THEN civilian delay increases by sufficient margin relative to baseline
- ğŸ”§ **SYSTEM INTEGRITY:** GIVEN a full simulation with emergency and civilian traffic, WHEN the system runs a small trial for some minutes, THEN no software crashes occur and logs of EV events are complete[1]

## ğŸ‘¥ Stakeholders and RACI

**ğŸ¤ Stakeholders:** Suraksha Squad team members, Project Mentor (faculty advisor), and University administration. The RL solution ultimately serves emergency responders and drivers/public.[1]

| ğŸ“‹ Activity | ğŸ‘¤ Responsible (R) | ğŸ“Š Accountable (A) | ğŸ’¬ Consulted (C) | â„¹ï¸ Informed (I) |
|-------------|-------------------|-------------------|------------------|-----------------|
| Requirements and planning | Shubhansh Gupta | Shubhansh Gupta | Mentor | Team |
| System Design (Algorithm / UI) | Team (Shubhansh, Rachit) | Shubhansh Gupta | Mentor | Team |
| RL Model Development | Shubhansh Gupta | Shubhansh Gupta | Rachit Gupta, Mentor | Team |
| Simulation & Backend Dev | Rachit Gupta | Rachit Gupta | Manas Kashyap, Mentor | Team |
| Integration (RL + Front-end) | Manas Kashyap | Manas Kashyap | Shubhansh, Rachit, Mentor | Team |
| Testing & Validation | Team | Shubhansh Gupta | Mentor | Team |
| Final Review & Delivery | Team | Suraksha Squad | Mentor | Mentor |

## ğŸ‘¨â€ğŸ’» Team and Roles

| ğŸ‘¤ Member | ğŸ­ Role | ğŸ“‹ Responsibilities | ğŸ› ï¸ Key Skills | â° Availability (hr/week) | ğŸ“§ Contact |
|-----------|---------|-------------------|---------------|-------------------------|-----------|
| Shubhansh Gupta | ğŸ§  RL Model Developer | Define state/action space, design reward, train RL algorithms; simulate EV scenarios | Python, TensorFlow/PyTorch, ML, SUMO | 15 | shubhansh.gupta_cs.aiml23@gla.ac.in |
| Rachit Gupta | ğŸ’» Full Stack Developer | Implement simulation interface, detection logic, control APIs; build dashboards | Node.js, Python, React, Databases | 15 | rachit.gupta_cs.aiml23@gla.ac.in |
| Manas Kashyap | ğŸ”§ Integration Engineer | Integrate RL agent with simulation; coordinate modules; write test harnesses | System integration, Python, APIs | 15 | manas.kashyap_cs.aiml23@gla.ac.in |

## ğŸ“… Weekwise Plan and Assignments

### ğŸ“… Week 1 (Sep 8 â€“ Sep 14): Requirements & Architecture
**ğŸ¯ Goals:** Define detailed requirements and RL problem (states, actions, rewards). Outline system architecture (interactions between GPS detection, RL agent, traffic lights).[1]

**ğŸ“‹ Tasks:**
- ğŸ‘¤ **Shubhansh:** drafts RL agent design
- ğŸ‘¤ **Rachit:** sets up base traffic simulation environment and mock GPS feed
- ğŸ‘¤ **Manas:** sketches integration points

**ğŸ“¦ Deliverables:** Requirement spec document, high-level design, initial simulation prototype[1]

### ğŸ“… Week 2 (Sep 15 â€“ Sep 21): Simulation Setup & Baseline
**ğŸ¯ Goals:** Build or configure an intersection simulation (e.g. one junction) with civilian traffic. Implement baseline fixed-time controller and simple EV-preemption rule for comparison.[1]

**ğŸ“‹ Tasks:**
- ğŸ‘¤ **Shubhansh:** codes environment interface for RL (defines traffic state representation)
- ğŸ‘¤ **Rachit:** implements EV detection trigger (simulated GPS input)
- ğŸ‘¤ **Manas:** tests end-to-end loop on one intersection

**ğŸ“¦ Deliverables:** Running simulation model, baseline controller, documented test scenarios[1]

### ğŸ“… Week 3 (Sep 22 â€“ Sep 28): RL Agent Prototype
**ğŸ¯ Goals:** Develop a basic RL agent (e.g. DQN) that controls traffic signals without EV logic. Train on simple scenarios.[1]

**ğŸ“‹ Tasks:**
- ğŸ‘¤ **Shubhansh:** implements and trains RL algorithm on small traffic patterns
- ğŸ‘¤ **Rachit:** extends simulation to multiple lanes
- ğŸ‘¤ **Manas:** begins logging metrics

**ğŸ“¦ Deliverables:** Trained RL model without EV priority, evaluation report (queue lengths, delays)[1]

### ğŸ“… Week 4 (Sep 29 â€“ Oct 5): Incorporate EV Priority
**ğŸ¯ Goals:** Modify RL reward to include EV clearance. Test EV scenarios.[1]

**ğŸ“‹ Tasks:**
- ğŸ‘¤ **Shubhansh:** updates reward function to heavily prioritize EV passage
- ğŸ‘¤ **Rachit:** ensures simulation generates EV vehicles and assigns priority flag
- ğŸ‘¤ **Manas:** integrates EV detection feed to RL agent

**ğŸ“¦ Deliverables:** Enhanced RL model with EV rewards, scenario demonstration (ambulance passes)[1]

### ğŸ“… Week 5 (Oct 6 â€“ Oct 12): Advanced Features
**ğŸ¯ Goals:** Add traffic flow prediction and dynamic rerouting logic. Implement a simple predictor (e.g. using historical sim data) to inform RL (optional) or route drivers around congested intersections when EV is incoming.[1]

**ğŸ“‹ Tasks:**
- ğŸ‘¤ **Shubhansh:** experiments with multi-step lookahead in RL
- ğŸ‘¤ **Rachit:** prototypes a rerouting module (e.g. Markov reroute)
- ğŸ‘¤ **Manas:** validates combined system

**ğŸ“¦ Deliverables:** Module for traffic prediction/rerouting, updated performance metrics[1]

### ğŸ“… Week 6 (Oct 13 â€“ Oct 19): System Integration & UI
**ğŸ¯ Goals:** Finalize integration of all components. Build a basic dashboard or logs for the virtual city traffic control center to view system status.[1]

**ğŸ“‹ Tasks:**
- ğŸ‘¤ **Rachit:** creates a simple web UI or data API for control center
- ğŸ‘¤ **Manas:** conducts full-system tests
- ğŸ‘¤ **Shubhansh:** refines RL training for stability

**ğŸ“¦ Deliverables:** Integrated end-to-end system, user interface prototype, midterm demo[1]

### ğŸ“… Week 7 (Oct 20 â€“ Oct 26): Testing & Optimization
**ğŸ¯ Goals:** Run extensive simulations to evaluate performance under varied conditions (different traffic volumes, EV arrival rates). Tune RL parameters for reliability.[1]

**ğŸ“‹ Tasks:** All team members run experiments and collect data
- ğŸ‘¤ **Shubhansh:** optimizes model parameters
- ğŸ‘¤ **Rachit and Manas:** identify and fix bugs

**ğŸ“¦ Deliverables:** Test report with graphs (EV response time, average delay), bug fix log[1]

### ğŸ“… Week 8 (Oct 27 â€“ Nov 2): Finalization & Demo
**ğŸ¯ Goals:** Prepare final demonstration and report. Conduct a full demo to mentor (including scenarios with multiple EVs).[1]

**ğŸ“‹ Tasks:** Finalize code, write user manual, polish slides and documentation

**ğŸ“¦ Deliverables:** Demo-ready system (v1.0), slide deck, final synopsis[1]

**ğŸ“ Note:** Weekly status updates will be shared with the mentor, and code/version control (Git) will be used throughout.[1]

## ğŸ‘¥ Users and UX

### ğŸ­ Personas

- ğŸš‘ **Ambulance Driver (Emergency Responder):** Needs quick, uninterrupted passage through intersections. Values speed and reliability
- ğŸš’ **Fire/Police Vehicle Operator:** Similar needs as ambulance, with highest priority in certain scenarios
- ğŸ›ï¸ **Traffic Control Center Operator:** Monitors city traffic; needs visibility into intersection status and EV movements. Values system reliability and interpretability
- ğŸš— **Civilian Driver:** Typical commuter. Wants reasonable travel times and fairness (not feeling "stuck" for too long)
- ğŸ§ª **Simulation Developer/Tester:** (Internal) Uses system to test scenarios. Values control over simulation parameters[1]

### ğŸ›£ï¸ Top User Journeys

#### ğŸš‘ Emergency Vehicle (Path Clearing)
An ambulance is dispatched and enters the simulation. The detection module identifies it via GPS. The RL controller immediately gives green signals along its route while holding cross-traffic. The ambulance smoothly traverses multiple intersections with minimal stops, arriving faster.[1]

#### ğŸ›ï¸ City Controller Monitoring
The city operator views a dashboard. When an emergency event occurs, they see the EV's location and system status. They may overlay predicted traffic flow and review signal adjustments. In case of anomalies, they can pause or adjust the simulation.[1]

#### ğŸš— Civilian Commuter
A driver on route sees normal signal operation. If an EV approaches a nearby intersection, they might see lights change to red earlier than expected. The system ensures that civilian detours remain reasonable, and traffic flow does not collapse.[1]

### ğŸ“– User Stories

#### ğŸš‘ Emergency Vehicle Priority
> **"As an ambulance driver, I want approaching intersections to turn green for me, so that I reach patients as fast as possible."**

**GIVEN** an emergency vehicle is detected 100 m from an intersection, **WHEN** it is 5 s from the stop line, **THEN** the corresponding traffic light turns green (and conflicting lights turn red) with â‰¤3 s of processing delay.[1]

#### âš–ï¸ Civilian Fairness
> **"As a civilian driver, I want fair treatment during emergencies, so my wait doesn't become excessive."**

**GIVEN** both an ambulance and a civilian vehicle are queued at an intersection, **WHEN** the ambulance is given priority, **THEN** the civilian will be released by the next green cycle, and its wait time remains within 20% of typical.[1]

#### ğŸ›ï¸ Traffic Control Monitoring
> **"As a traffic control operator, I want real-time insights into traffic and emergencies, so I can trust the system."**

**GIVEN** the system is running, **WHEN** an EV event occurs, **THEN** the dashboard updates within 1 s with EV status and planned signal changes.[1]

*(Accessibility & localization are minimal since this is a simulation interface used by technical staff; interface will be in English with standard UI controls.)*[1]

## ğŸª Market and Competitors

### ğŸ­ Competitors

#### â° Fixed-Time Controllers
Pre-programmed cycles (e.g. green/yellow/red patterns)
- **ğŸ’ª Strength:** Simple, widely used
- **âš ï¸ Weakness:** Cannot adapt to real-time conditions or EVs at all[1]

#### ğŸ“Š Adaptive Flow Systems (e.g. SCOOT, SCATS)
Adjust signal timing based on sensors/traffic detectors
- **ğŸ’ª Strength:** Improve average flow
- **âš ï¸ Weakness:** Do not specifically expedite emergency vehicles[1]

#### ğŸš¨ Emergency Vehicle Preemption (GPS/RFID-based)
Specialized devices allow EVs to trigger green lights on approach
- **ğŸ’ª Strength:** EVs get quick passage
- **âš ï¸ Weakness:** Typically ignore overall congestion â€“ often causing backups elsewhere[1]

#### ğŸ”¬ Research Prototypes
Several academic RL projects exist for traffic lights, but few integrate EV priority. For example, some use deep learning for urban signal control, but usually focus on congestion broadly.[1]

### ğŸ¯ Positioning

#### ğŸŒŸ Our Differentiator
We combine real-time emergency detection with adaptive RL control. The system not only gives right-of-way to EVs but learns over time to do so without crippling civilian traffic. In contrast to static preemption, our solution continuously optimizes for both objectives. In summary, no existing product fully unites RL optimization with emergency prioritization in the way we propose.[1]

## ğŸ¯ Objectives and Success Metrics

### ğŸš‘ O1: Minimize Emergency Response Time
- **ğŸ¯ Target:** â‰¥30% reduction in average travel time for emergency vehicles compared to fixed signals
- **ğŸ“Š KPI:** Average EV travel time (seconds) in simulation[1]

### ğŸ“Š O2: Optimize Traffic Flow
- **ğŸ¯ Target:** â‰¥15% improvement in average throughput (vehicles/hour) or similar reduction in overall delay
- **ğŸ“Š KPI:** Average delay per non-EV vehicle (seconds)[1]

### âš–ï¸ O3: Fairness Between EV and Civilian Traffic
- **ğŸ¯ Target:** Ensure non-emergency average delay does not degrade more than 20% when EVs are prioritized
- **ğŸ“Š KPI:** Ratio of delay (with EV priority) / (delay baseline)[1]

### ğŸ¯ O4: EV Detection Accuracy
- **ğŸ¯ Target:** â‰¥99% of simulated EVs are correctly detected by GPS module
- **ğŸ“Š KPI:** EV detection success rate[1]

### ğŸ§  O5: RL Convergence
- **ğŸ¯ Target:** Agent reaches stable performance (e.g. converged reward) within set episodes
- **ğŸ“Š KPI:** Reward stability (variance) after training[1]

### â›½ O6: Fuel/Idle Reduction
- **ğŸ¯ Target:** Measurable reduction in total vehicle idle time (e.g. minutes) compared to baseline, which correlates to fuel savings
- **ğŸ“Š KPI:** Total idle time or fuel usage estimate[1]

These will be measured during simulation experiments. For instance, prior work shows RL can improve "transport efficiency" and sustainability significantly, setting a benchmark for our targets.[1]

## â­ Key Features

### ğŸ§  Adaptive RL-Based Scheduling (Must)
The core feature. The system's RL agent observes current traffic state (queue lengths, EV presence) and decides signal phases adaptively.
- **âœ… Acceptance:** In simulation trials, the RL controller must produce lower average delay than a fixed schedule under identical traffic inputs[1]

### ğŸ“¡ Real-Time Emergency Vehicle Detection (Must)
Simulated GPS signals identify EVs. The system must recognize an EV's approach instantly.
- **âœ… Acceptance:** GIVEN an EV enters detection range, the system marks it as high-priority within 1 s, and triggers priority logic[1]

### ğŸ—ºï¸ Dynamic Rerouting Support (Should)
If an EV's path is blocked by congestion, the system suggests alternative routes to following vehicles.
- **âœ… Acceptance:** GIVEN a congested path ahead, WHEN EV is en route, THEN backup routes are computed so that EV ETA is reduced (compared to no reroute)[1]

### ğŸš— Vehicle Queue Management (Must)
The controller manages queues fairly. Civilian vehicles are queued if needed, and EV queues are cleared first.
- **âœ… Acceptance:** GIVEN simultaneous queues, WHEN EV is present, THEN EV-facing lights turn green while queuing civilians do not exceed acceptable wait times[1]

### ğŸ”® Predictive Traffic Analytics (Could)
The system analyzes past traffic flow to forecast congestion (e.g. using a simple LSTM or statistical model) and adjusts RL training or routing.
- **âœ… Acceptance:** The predictive model achieves reasonable accuracy (e.g. 85% hit rate) on simulated flow, improving decision-making efficiency[1]

### ğŸŒ Backend Communication with City Control (Should)
Bi-directional data interface with a traffic center.
- **âœ… Acceptance:** The simulation logs and dashboard update in real time (â‰¤2 s lag) with traffic stats and EV events, enabling oversight[1]

Each feature's implementation will rely on key dependencies (RL framework, simulation, mapping API). For example, scheduling depends on a trained neural network; detection depends on simulated GPS feeds. We will use acceptance tests as in Section 2 to verify each feature.[1]

## ğŸ—ï¸ Architecture

The system follows a modular architecture:

### ğŸ™ï¸ Traffic Simulation Environment
A virtual city/intersection simulation (e.g. SUMO) generates vehicle traffic (both civilian and EV). Road network and vehicle behaviors (speeds, routes) are modeled here.[1]

### ğŸ“¡ Detection Module
Simulated GPS data from vehicles is processed to identify emergency vehicles. Detected EVs send priority flags to the controller.[1]

### ğŸ§  RL Signal Controller (Core Engine)
Implements the RL agent. It receives state inputs (current light states, queue lengths, detected EVs) and outputs actions (which direction to green-light next). The agent may run on a loop of stateâ†’actionâ†’environment update.[1]

### ğŸš¦ Traffic Actuator
Interface to the simulation's traffic lights. It applies the RL controller's decisions by changing the signals in the simulation.[1]

### ğŸ›ï¸ City Traffic Control Interface
A backend/dashboard that collects data (logs of events, traffic metrics) and allows operators to monitor or optionally override (e.g. emergency override).[1]

### ğŸ“Š Data Storage & Analytics
Logs events (timestamped state/action/reward) for analysis. Could be a simple database or log files.[1]

### ğŸ”„ Workflow
An example sequence is: EV enters road â†’ detection module flags EV â†’ RL controller (in response) sets signal to green for EV â†’ actuator changes light â†’ vehicle moves â†’ traffic state updates (feedback to RL). Another flow: regular traffic updates cycle, and RL agent optimizes throughput if no EV present.[1]

## ğŸ“Š Data Design

We will log key data elements for each simulation run:

### ğŸš¦ Intersection Status
**ğŸ“‹ Attributes:** {intersection_id, timestamp, current_phase, queue_lengths}[1]

### ğŸš— Vehicle Events
**ğŸ“‹ Attributes:** {vehicle_id, type (civilian/ambulance/fire/police), position, speed, direction, timestamp}. EVs have priority_flag = true[1]

### ğŸ§  RL Agent Logs
**ğŸ“‹ Attributes:** {episode_id, step, state_representation, action_taken, reward}[1]

### ğŸ“Š Traffic Metrics
Summarized data per run: average delay, throughput, EV travel times[1]

Data will be stored in CSV or simple tables. No personal/sensitive information is used (only simulated vehicle IDs). Backup logs nightly; ensure ability to reproduce scenarios from recorded seed values.[1]

## ğŸ“ˆ Technical Workflow Diagrams

### ğŸ”„ State Transition Diagram
*[Diagram placeholder - refer to original document]*[1]

### ğŸ“Š Sequence Diagram
*[Diagram placeholder - refer to original document]*[1]

### ğŸ‘¥ Use Case Diagram
*[Diagram placeholder - refer to original document]*[1]

### ğŸŒŠ Data Flow Diagram
*[Diagram placeholder - refer to original document]*[1]

### ğŸ—‚ï¸ ER Diagram
*[Diagram placeholder - refer to original document]*[1]

### âš™ï¸ Technical Workflow Diagram
*[Diagram placeholder - refer to original document]*[1]

### ğŸ—ï¸ Work Architecture Diagram
*[Diagram placeholder - refer to original document]*[1]

## ğŸ” Quality (Non-Functional Requirements and Testing)

### ğŸ“Š Non-Functional Requirements

| ğŸ“Š Metric | ğŸ¯ SLI / Target | ğŸ“ Measurement |
|-----------|----------------|----------------|
| â±ï¸ Availability | 99% uptime in simulation runs | Automated uptime monitoring |
| âš¡ Real-Time Latency | Decision â‰¤1 s after EV detection | Log timestamp differences |
| ğŸ”§ Reliability | No critical bugs (0% crashes) | Pass/fail in test environment |
| ğŸ¯ EV Detection Accuracy | â‰¥99% | Compare detected vs actual EVs |
| ğŸ“Š Throughput | Maintain â‰¥ baseline | Vehicles/hour (simulation stats) |
| ğŸ”’ Security | Secure channels (TLS) | (Assume secure communication) |
| ğŸ“ Logging Integrity | 100% event logging retention (7 days) | Log completeness check |

### ğŸ§ª Test Plan

#### ğŸ§  RL Module (Unit Tests)
Test individual functions â€“ state encoding, reward calculation, neural network outputs
- **ğŸ› ï¸ Tool:** PyTest/TensorFlow tests
- **ğŸ‘¤ Owner:** Shubhansh (Coverage â‰¥80%)
- **ğŸšª Exit:** All critical assertions pass, no errors[1]

#### ğŸ”— Detection/Integration (Integration Tests)
Simulate EV approach and verify detectionâ†’priority pipeline
- **ğŸ› ï¸ Tool:** Custom simulation scenarios, Postman for APIs
- **ğŸ‘¤ Owner:** Manas (100% of EV cases)
- **ğŸšª Exit:** EVs always trigger priority within timing threshold[1]

#### ğŸŒ System (End-to-End Tests)
Run full simulation with mixed traffic
- **ğŸ› ï¸ Tool:** SUMO or custom scenario runner
- **ğŸ‘¤ Owner:** Team (Shubhansh & Rachit)
- **ğŸ“Š Coverage:** Key scenarios (rush hour, random EVs) complete
- **ğŸšª Exit:** Metrics (delay, EV time) meet acceptance criteria[1]

#### âš¡ Performance Tests
Measure latency of controller decisions under load
- **ğŸ› ï¸ Tool:** Logging, APM
- **ğŸ‘¤ Owner:** Rachit
- **ğŸšª Exit:** Latency stays within SLAs in stress tests[1]

### ğŸŒ Environments

- **ğŸ’» Development:** Each member runs code locally with lightweight simulator, controlled branch on GitHub
- **ğŸ”§ Staging:** Central integration environment (e.g. lab server) where combined system is deployed for testing
- **ğŸš€ Production/Demo:** Final version on lab machine or cloud VM with necessary simulation tools[1]

Feature flags will control experimental features; rollbacks are managed via version control.[1]

## ğŸ” Security and Compliance

### âš ï¸ Threat Model

| ğŸ›¡ï¸ Asset | ğŸš¨ Threat | ğŸ“Š STRIDE (Category) | ğŸ”§ Mitigation | ğŸ‘¤ Owner |
|-----------|-----------|---------------------|---------------|----------|
| Signal Commands | Tampering with commands | Tampering (T) | Use SSL/TLS for control messages; validate inputs | Rachit |
| EV detection data | Spoofed EV signal (false flag) | Spoofing (S) | Assume authenticated GPS feed; ignore unrealistic inputs | Rachit |
| System Access | Unauthorized code changes | Elevation of Privilege (E) | Restrict repository access, use strong credentials | Manas |

### ğŸ” AuthN / AuthZ
Only team members have commit access to code repositories. No public user accounts are needed. The traffic control interface (if web-based) will be secured for team use only.[1]

### ğŸ“‹ Audit and Logging
All EV detections, signal changes, and admin actions are logged with timestamps. Logs are retained for 2 weeks for analysis. No real personal data is used. Logs contain only simulated vehicle data. Compliance with university data policy is ensured (no third-party data collection or sharing).[1]

### ğŸ“œ Compliance
This is an academic project; it follows GLA University's IT policy. No external user data is involved, and no known regulatory compliance (e.g. GDPR) applies here. We will cite all incorporated third-party code and respect open-source licenses.[1]

## ğŸš€ Delivery and Operations

### ğŸ“… Release Plan

#### ğŸ¯ Milestone
v1.0 Demo by end of Week 8 (Nov 2)[1]

#### ğŸ”„ Internal Releases
- **ğŸ…°ï¸ Alpha by Week 3** (basic RL without EV logic)
- **ğŸ…±ï¸ Beta by Week 5** (with EV integration)[1]

Each release will have release notes summarizing features and any outstanding issues. The mentor will approve progression to the next stage.[1]

### ğŸ”„ CI/CD and Rollback

#### ğŸ”§ CI/CD Pipeline
Commits to main trigger automated tests (unit and integration). Passing builds are deployed to the staging environment nightly.[1]

#### ğŸ› ï¸ Tools
GitHub Actions (or GitLab CI) for linting, testing, and packaging.[1]

#### â†©ï¸ Rollback
Use Git tags/releases. If a build fails validation, revert to the previous tag and debug.[1]

### ğŸ“Š Monitoring and Alerting
In simulation, monitoring is minimal. We will log key metrics (queue lengths, EV response times) and manually review them. If latency or errors spike, alerts (e.g. email to team) are triggered by a simple watchdog script.[1]

### ğŸ“¢ Communication Plan

- **ğŸ—£ï¸ Stand-ups:** Brief (15-min) video calls every Monday/Wednesday/Friday to sync progress
- **ğŸ“„ Weekly Reports:** Summary of achievements and issues submitted to mentor each Friday
- **ğŸ‘¨â€ğŸ« Mentor Meetings:** Biweekly demos (end of Week 4 and Week 8) to present prototypes and gather feedback[1]

## âš ï¸ Risks and Mitigations

### ğŸ§  RL Training Instability
- **âš ï¸ Risk:** The agent may not converge or may converge to suboptimal policies
- **ğŸ›¡ï¸ Mitigation:** Start with simple scenarios; tune hyperparameters; if needed, use tried-and-true algorithms (e.g. DQN) and curriculum learning (gradually increase complexity)[1]

### ğŸ® Insufficient Simulation Fidelity
- **âš ï¸ Risk:** Simulation may not reflect real traffic complexities
- **ğŸ›¡ï¸ Mitigation:** Calibrate parameters (e.g. arrival rates) using standard distributions; compare baseline system performance to known benchmarks[1]

### â° Time Overrun
- **âš ï¸ Risk:** 30 hours/week may be too little for all tasks
- **ğŸ›¡ï¸ Mitigation:** Prioritize core features (EV priority + RL); defer non-critical features (e.g. advanced UI) if behind schedule. Use open-source modules to save time[1]

### ğŸ”— Integration Bugs
- **âš ï¸ Risk:** Modules (RL, detection, UI) may not interface smoothly
- **ğŸ›¡ï¸ Mitigation:** Integrate early and incrementally. Allocate time each week for end-to-end testing[1]

### ğŸ’» Compute/Resource Limitations
- **âš ï¸ Risk:** Training deep RL could be slow on available hardware
- **ğŸ›¡ï¸ Mitigation:** Use efficient algorithms, reduce state/action space if needed, or leverage cloud credits/minor GPU access for heavy runs[1]

Risk severity will be tracked weekly and addressed by adjusting scope or plan as needed.[1]

## ğŸ“Š Evaluation Strategy and Success Metrics

We will evaluate the system primarily via simulation experiments:

### ğŸ“ˆ Baseline Comparison
Run the same traffic scenario with (a) fixed-time signals, (b) heuristic EV preemption, and (c) our RL controller. Compare metrics: Average EV travel time, Average civilian delay, Total vehicles served, and Total idle time.[1]

### ğŸ”¥ Stress Testing
Test edge cases, e.g. many simultaneous EVs, peak-hour congestion, to ensure stability.[1]

### ğŸ¯ Success Benchmarks
Meet or exceed the targets set in Section 8. For example, demonstrating that EV travel time under RL is significantly lower than baseline, and that throughput is not sacrificed.[1]

### ğŸ“Š Reporting
Prepare plots of key metrics over time/episodes. Document scenarios where RL provides clear benefits.[1]

### ğŸ’­ Qualitative Feedback
If possible, have a domain expert (e.g. traffic engineer) review the approach. Include lessons and limitations in the final report.[1]

In summary, success is measured by achieving the key goals with quantitative gains (as informed by literature) and validating that emergency vehicles indeed receive priority without critically harming normal traffic flow.[1]

## ğŸ“š Appendices

### ğŸ“– Glossary

- **ğŸ§  RL (Reinforcement Learning):** A type of machine learning where an agent learns optimal actions by interacting with an environment and receiving rewards/penalties
- **ğŸš¨ EV (Emergency Vehicle):** Special vehicles like ambulances, fire trucks, and police cars that require immediate right-of-way
- **ğŸ”„ MDP (Markov Decision Process):** A mathematical framework used to model decision-making in RL problems
- **ğŸ§  DQN (Deep Q-Network):** A reinforcement learning algorithm that uses neural networks to approximate Q-values
- **ğŸ“ GPS (Global Positioning System):** Satellite-based system used to detect vehicle locations
- **ğŸ“Š Throughput:** Number of vehicles passing through an intersection in a given period
- **â° Idle Time:** Duration for which vehicles remain stationary at a red light
- **ğŸ”§ SCOOT/SCATS:** Existing adaptive traffic signal systems used in real cities
- **ğŸ™ï¸ SUMO (Simulation of Urban Mobility):** An open-source traffic simulation software
- **â° ETA (Estimated Time of Arrival):** Predicted arrival time of a vehicle at a destination[1]

### ğŸ“š References

- Sutton, R.S. and Barto, A.G. Reinforcement Learning: An Introduction. MIT Press, 2018
- Khamis, A., et al. "Intelligent Traffic Light Control System Using Reinforcement Learning." Journal of Advanced Transportation, 2020
- Van der Pol, E., & Oliehoek, F. "Coordinated Deep Reinforcement Learners for Traffic Light Control." NIPS Workshop on Learning, Inference and Control of Multi-Agent Systems, 2016
- SUMO Documentation â€“ Simulation of Urban Mobility. Available: https://www.eclipse.org/sumo/
- Chen, Y., et al. "Deep Reinforcement Learning for Urban Traffic Light Control." ICLR, 2019
- Google Maps & GPS Technology â€“ Vehicle location and routing references
- University lecture notes and course material from CSE (AI/ML and IoT), GLA University
